name: CI Pipeline

permissions:
  contents: read
  checks: write
  pull-requests: write
  security-events: write

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master, develop ]
  workflow_dispatch:

jobs:
  changes:
    runs-on: ubuntu-latest
    outputs:
      python: ${{ steps.changes.outputs.python }}
    steps:
    - uses: actions/checkout@v4
    - name: Check for Python changes
      id: changes
      uses: dorny/paths-filter@v3
      with:
        filters: |
          python:
            - '**/*.py'
            - 'requirements*.txt'
            - 'pyproject.toml'
            - 'tox.ini'
            - '.github/workflows/**'

  test:
    runs-on: ${{ matrix.os }}
    needs: changes
    if: needs.changes.outputs.python == 'true'
    permissions:
      contents: read
      checks: write
      pull-requests: write
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.9", "3.10", "3.11", "3.12", "3.13"]
        exclude:
          # Reduce matrix size for faster builds
          - os: macos-latest
            python-version: "3.9"
          - os: macos-latest
            python-version: "3.10"
          - os: windows-latest
            python-version: "3.9"
            
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.cache/playwright
          .mypy_cache
          .pytest_cache
        key: ${{ runner.os }}-deps-${{ matrix.python-version }}-${{ hashFiles('**/requirements-test.txt', '**/pyproject.toml', '**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-deps-${{ matrix.python-version }}-
          ${{ runner.os }}-deps-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov tox
        pip install -r requirements-test.txt
        
    - name: Install Playwright (optional)
      run: |
        pip install "playwright>=1.45.0" || echo "Playwright installation failed, continuing without it"
      continue-on-error: true
        
    - name: Install Playwright browsers (if needed)
      run: |
        playwright install
      continue-on-error: true
        
    - name: Run tests with pytest
      run: |
        pytest --cov=data_processing --cov=data_acquisition --cov=visualization --cov=config --cov-report=xml --cov-report=term-missing --junitxml=test-results.xml -v tests/
      shell: bash
        
    - name: Publish Test Results
      uses: dorny/test-reporter@v1.9.1
      if: (success() || failure()) && hashFiles('test-results.xml') != ''
      with:
        name: Test Results (${{ matrix.python-version }} on ${{ matrix.os }})
        path: test-results.xml
        reporter: java-junit
        fail-on-error: false
      continue-on-error: true
        
    - name: Parse Test Results (Fallback)
      if: (success() || failure()) && hashFiles('test-results.xml') != ''
      shell: python
      run: |
        import xml.etree.ElementTree as ET
        import os
        
        if os.path.exists('test-results.xml'):
            try:
                tree = ET.parse('test-results.xml')
                root = tree.getroot()
                tests = root.get('tests', '0')
                failures = root.get('failures', '0')
                errors = root.get('errors', '0')
                
                print(f"Tests: {tests}, Failures: {failures}, Errors: {errors}")
            except Exception as e:
                print(f"Could not parse test results: {e}")
        
    - name: Generate Test Summary
      if: always()
      shell: python
      run: |
        # Don't write individual job results to main summary
        # All reporting will be handled by the summary job
        print(f"✅ Python ${{ matrix.python-version }} on ${{ matrix.os }} test job completed")
        
    - name: Upload Test Artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}-${{ matrix.os }}
        path: |
          htmlcov/
          test-results.xml
          coverage.xml
          .coverage
        retention-days: 30
        
    - name: Upload coverage to Codecov
      if: matrix.python-version == '3.12' && matrix.os == 'ubuntu-latest'
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
        
    - name: Coverage Report PR Comment
      if: github.event_name == 'pull_request' && matrix.python-version == '3.12' && matrix.os == 'ubuntu-latest'
      uses: py-cov-action/python-coverage-comment-action@v3
      with:
        GITHUB_TOKEN: ${{ github.token }}

  lint:
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.python == 'true'
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.12
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
        
    - name: Install linting dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black isort mypy types-tabulate
        
    - name: Run flake8
      id: flake8
      run: flake8 data_processing data_acquisition visualization config tests --max-line-length=88 --extend-ignore=E203,W503
      continue-on-error: true
      
    - name: Check code formatting with black
      id: black
      run: black --check data_processing data_acquisition visualization config tests
      continue-on-error: true
      
    - name: Check import sorting with isort
      id: isort
      run: isort --check-only data_processing data_acquisition visualization config tests --profile black
      continue-on-error: true
      
    - name: Run mypy type checking
      id: mypy
      run: mypy data_processing data_acquisition visualization config --ignore-missing-imports
      continue-on-error: true
      
    - name: Generate Lint Summary
      if: always()
      run: |
        echo "## 🔍 Code Quality Results" >> $GITHUB_STEP_SUMMARY
        echo "| Tool | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| flake8 | ${{ steps.flake8.outcome == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| black | ${{ steps.black.outcome == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| isort | ${{ steps.isort.outcome == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| mypy | ${{ steps.mypy.outcome == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY

  security:
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.python == 'true'
    permissions:
      contents: read
      security-events: write
      actions: read
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.12
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
        
    - name: Install security scanning tools
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit
        
    - name: Run safety check
      id: safety
      run: safety check --file requirements.txt
      continue-on-error: true
      
    - name: Run bandit security scan
      id: bandit
      run: |
        # Run bandit and generate JSON report
        bandit -r data_processing data_acquisition visualization config -f json -o bandit-report.json || echo "Bandit scan completed with findings"
        # Convert to SARIF format
        python scripts/bandit_to_sarif.py bandit-report.json bandit-results.sarif
      continue-on-error: true
      
    - name: Upload SARIF to GitHub Security
      uses: github/codeql-action/upload-sarif@v3
      if: always() && hashFiles('bandit-results.sarif') != ''
      with:
        sarif_file: bandit-results.sarif
      continue-on-error: true
      
    - name: Generate Security Summary
      if: always()
      run: |
        echo "## 🔒 Security Scan Results" >> $GITHUB_STEP_SUMMARY
        echo "| Tool | Status | Details |" >> $GITHUB_STEP_SUMMARY
        echo "|------|--------|---------|" >> $GITHUB_STEP_SUMMARY
        echo "| Safety | ${{ steps.safety.outcome == 'success' && '✅ Passed' || '❌ Failed' }} | Dependency vulnerability scan |" >> $GITHUB_STEP_SUMMARY
        echo "| Bandit | ${{ steps.bandit.outcome == 'success' && '✅ Passed' || '❌ Failed' }} | Static security analysis |" >> $GITHUB_STEP_SUMMARY
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 📊 Security Scan Details" >> $GITHUB_STEP_SUMMARY
        python scripts/security_summary.py bandit-report.json >> $GITHUB_STEP_SUMMARY
      
    - name: Upload bandit report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          bandit-results.sarif
        retention-days: 30

  summary:
    runs-on: ubuntu-latest
    needs: [changes, test, lint, security]
    if: always() && needs.changes.outputs.python == 'true'
    permissions:
      pull-requests: write
      contents: read
      security-events: write
    steps:
    - name: Download test artifacts
      uses: actions/download-artifact@v4
      with:
        pattern: test-results-*
        merge-multiple: true
      continue-on-error: true
        
    - name: Generate Comprehensive Pipeline Summary
      shell: python
      run: |
        import os
        import xml.etree.ElementTree as ET
        import glob
        
        # Collect all test results
        test_files = glob.glob('test-results.xml') + glob.glob('**/test-results.xml', recursive=True)
        
        total_tests = 0
        total_failures = 0
        total_errors = 0
        total_time = 0.0
        failed_tests = []
        
        # Parse all test result files
        for file_path in test_files:
            try:
                tree = ET.parse(file_path)
                root = tree.getroot()
                
                tests = int(root.get('tests', '0'))
                failures = int(root.get('failures', '0'))
                errors = int(root.get('errors', '0'))
                time = float(root.get('time', '0'))
                
                total_tests += tests
                total_failures += failures
                total_errors += errors
                total_time += time
                
                # Collect failed test details
                if failures > 0 or errors > 0:
                    for testcase in root.findall('.//testcase'):
                        failure = testcase.find('failure')
                        error = testcase.find('error')
                        if failure is not None or error is not None:
                            name = testcase.get('name', 'Unknown')
                            classname = testcase.get('classname', '')
                            failed_tests.append(f"{classname}::{name}")
            except Exception as e:
                print(f"Error parsing {file_path}: {e}")
        
        # Generate summary
        with open(os.environ['GITHUB_STEP_SUMMARY'], 'w', encoding='utf-8') as f:
            f.write("# 🚀 CI Pipeline Summary\n\n")
            
            # Overall status
            all_passed = '${{ needs.test.result }}' == 'success' and '${{ needs.lint.result }}' == 'success' and '${{ needs.security.result }}' == 'success'
            status_emoji = "✅" if all_passed else "⚠️"
            status_text = "All checks passed! Ready to merge." if all_passed else "Some checks failed. Please review."
            
            f.write(f"## {status_emoji} {status_text}\n\n")
            
            # Job results table
            f.write("## 📊 Results\n\n")
            f.write("| Job | Status |\n")
            f.write("|-----|--------|\n")
            f.write("| 🧪 Tests | ${{ needs.test.result == 'success' && '✅ Passed' || '❌ Failed' }} |\n")
            f.write("| 🔍 Linting | ${{ needs.lint.result == 'success' && '✅ Passed' || '❌ Failed' }} |\n")
            f.write("| 🔒 Security | ${{ needs.security.result == 'success' && '✅ Passed' || '❌ Failed' }} |\n\n")
            
            # Failed tests (if any)
            if failed_tests:
                f.write("## ❌ Failed Tests\n")
                for test in failed_tests[:5]:  # Limit to 5
                    f.write(f"- {test}\n")
                if len(failed_tests) > 5:
                    f.write(f"- ... and {len(failed_tests) - 5} more\n")
                f.write("\n")
            
            # Pipeline metrics
            f.write("## � Pipeline Metrics\n\n")
            f.write("| Metric | Value |\n")
            f.write("|--------|-------|\n")
            f.write("| Workflow Run | [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) |\n")
            f.write("| Triggered By | ${{ github.event_name }} |\n")
            f.write("| Branch | ${{ github.ref_name }} |\n")
            f.write("| Commit | [\`${{ github.sha }}\`](${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }}) |\n")

    - name: Comment PR with Results
      if: github.event_name == 'pull_request'
      uses: marocchino/sticky-pull-request-comment@v2
      with:
        message: |
          # 🚀 CI Pipeline Results
          
          ## Status Overview
          | Job | Status | Details |
          |-----|--------|---------|
          | 🧪 Tests | ${{ needs.test.result == 'success' && '✅ Passed' || '❌ Failed' }} | Cross-platform testing |
          | 🔍 Linting | ${{ needs.lint.result == 'success' && '✅ Passed' || '❌ Failed' }} | Code quality checks |
          | 🔒 Security | ${{ needs.security.result == 'success' && '✅ Passed' || '❌ Failed' }} | Security scanning |
          
          ${{ (needs.test.result == 'success' && needs.lint.result == 'success' && needs.security.result == 'success') && '### 🎉 All checks passed! Ready to merge.' || '### ⚠️ Some checks failed. Please review the errors.' }}
          
          ---
          **Workflow:** [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) | **Commit:** ${{ github.sha }} | **Branch:** ${{ github.head_ref }}

    - name: Set final status
      run: |
        echo "📊 Pipeline completed"
        echo "- Tests: ${{ needs.test.result }}"
        echo "- Linting: ${{ needs.lint.result }}"
        echo "- Security: ${{ needs.security.result }}"
          ${{ (needs.test.result == 'success' && needs.lint.result == 'success' && needs.security.result == 'success') && '### 🎉 All checks passed! Ready to merge.' || '### ⚠️ Some checks failed. Please review the errors.' }}
          
          ---
          **Workflow:** [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) | **Commit:** ${{ github.sha }} | **Branch:** ${{ github.head_ref }}

    - name: Set final status
      run: |
        echo "📊 Final Results Summary:"
        echo "- Test job: ${{ needs.test.result }}"
        echo "- Lint job: ${{ needs.lint.result }}"
        echo "- Security job: ${{ needs.security.result }}"
        
        if [ "${{ needs.test.result }}" = "success" ] && [ "${{ needs.lint.result }}" = "success" ] && [ "${{ needs.security.result }}" = "success" ]; then
          echo "✅ Pipeline completed successfully"
        else
          echo "⚠️ Pipeline completed with some failures - check individual job results"
          echo "Note: This is informational only, individual jobs may have continue-on-error set"
        fi
        echo "Summary job completed"
          echo "Note: This is informational only, individual jobs may have continue-on-error set"
        fi
        echo "Summary job completed"
        if [ "${{ needs.test.result }}" = "success" ] && [ "${{ needs.lint.result }}" = "success" ] && [ "${{ needs.security.result }}" = "success" ]; then
          echo "✅ Pipeline completed successfully"
        else
          echo "⚠️ Pipeline completed with some failures - check individual job results"
          echo "Note: This is informational only, individual jobs may have continue-on-error set"
        fi
        echo "Summary job completed"
          echo "Note: This is informational only, individual jobs may have continue-on-error set"
        fi
        echo "Summary job completed"
